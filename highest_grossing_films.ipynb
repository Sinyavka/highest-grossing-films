{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "531d0f51-372b-4340-9ae6-5adc66ecb358",
   "metadata": {},
   "source": [
    "## Helper function to clean and split directors and countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bfb320-bd19-4082-b324-c5e6479b0c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clear_and_split_text(text):\n",
    "    \"\"\"\n",
    "    Cleans and processes the input text by removing numerical references in square brackets,\n",
    "    normalizing line breaks, and concatenating lines into a single string separated by commas.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'\\[\\d+\\]', '\\n', text)\n",
    "\n",
    "    text = re.sub(r'\\n+', '\\n', text).strip()\n",
    "    texts = text.split('\\n')\n",
    "    res = texts[0]\n",
    "    for t in texts[1:]:\n",
    "        res += \", \" + t\n",
    "\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14145be7-2597-429b-a980-df445b8f28c4",
   "metadata": {},
   "source": [
    "# üé¨ Web Scraping: Highest-Grossing Films\n",
    "\n",
    "## Overview\n",
    "This script scrapes **Wikipedia's List of Highest-Grossing Films** to extract key details about top box-office movies, including:\n",
    "\n",
    "- üé• **Title**\n",
    "- üìÖ **Year of Release**\n",
    "- üí∞ **Box Office Earnings**\n",
    "- üîó **Wikipedia Link**\n",
    "- üé¨ **Director**\n",
    "- üåç **Country of Origin**\n",
    "\n",
    "## How It Works\n",
    "- Uses `requests` to fetch the Wikipedia page.\n",
    "- Parses the HTML using `BeautifulSoup` to extract film data from a table.\n",
    "- Retrieves additional details (director & country) from each film‚Äôs page.\n",
    "- Stores the results in a structured format JSON.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6874af07-d702-488f-b4da-e7fdfc00da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "URL = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "def get_film_data():\n",
    "    \"\"\"\n",
    "    Scrapes the Wikipedia page to retrieve a list of the highest-grossing films,\n",
    "    including their title, release year, box office earnings, Wikipedia link, director, and country.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries, each containing details about a film.\n",
    "    \"\"\"\n",
    "    response = requests.get(URL, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    table = soup.find(\"table\", {\"class\": \"wikitable\"})\n",
    "    rows = table.find_all(\"tr\")[1:]  \n",
    "    \n",
    "    films = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all([\"th\", \"td\"])\n",
    "\n",
    "        title_tag = cols[2].find(\"a\")\n",
    "        title = title_tag.text.strip() if title_tag else cols[2].text.strip()\n",
    "        link = \"https://en.wikipedia.org\" + title_tag[\"href\"] if title_tag else None\n",
    "        \n",
    "\n",
    "        year = int(cols[4].text.strip())\n",
    "        \n",
    "\n",
    "        box_office = int(extract_digits(cols[3].text.strip().replace(\"$\", \"\").replace(\",\", \"\")))\n",
    "        \n",
    "\n",
    "        director, country = get_film_details(link) if link else (None, None, None)\n",
    "        \n",
    "        films.append({\n",
    "            \"title\": title,\n",
    "            \"year\": year,\n",
    "            \"box_office\": box_office,\n",
    "            \"link\": link,\n",
    "            \"director\": director,\n",
    "            \"country\": country\n",
    "        })\n",
    "        \n",
    "\n",
    "    \n",
    "    return films\n",
    "\n",
    "def get_film_details(film_url):\n",
    "\n",
    "    \"\"\"\n",
    "    Extracts additional details about a film, such as director and country of origin,\n",
    "    from its Wikipedia page.\n",
    "\n",
    "    Parameters:\n",
    "    film_url (str): The Wikipedia URL of the film.\n",
    "\n",
    "    Returns:\n",
    "    tuple: (director, country) - The director and country information.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = requests.get(film_url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    info_box = soup.find(\"table\", {\"class\": \"infobox\"})\n",
    " \n",
    "    director = clear_and_split_text(extract_info(info_box, \"Directed by\"))\n",
    "    country = clear_and_split_text(extract_info(info_box, [\"Country\", \"Countries\"]))\n",
    "\n",
    "    \n",
    "    return director, country\n",
    "\n",
    "\n",
    "def extract_info(info_box, label):\n",
    "    \"\"\"\n",
    "    Extracts specific information from a Wikipedia infobox.\n",
    "\n",
    "    Parameters:\n",
    "    info_box (BeautifulSoup object): The infobox HTML element.\n",
    "    label (str or list): The label(s) of the information to extract.\n",
    "\n",
    "    Returns:\n",
    "    str: The extracted text, if found; otherwise, None.\n",
    "    \"\"\"\n",
    "    \n",
    "    row = info_box.find(\"th\", string=label)\n",
    "    if row:\n",
    "        td = row.find_next_sibling(\"td\")\n",
    "        return td.text.strip() if td else None\n",
    "    return None\n",
    "\n",
    "\n",
    "film_data = get_film_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e66eb-ce8d-4472-8865-21c0d31927e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in JSON\n",
    "with open(\"highest_grossing_films.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(film_data, f, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b64883-44e9-488a-b6be-390e75bb3559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6644dc83-3801-49b7-b08a-57efed8485d0",
   "metadata": {},
   "source": [
    "# üé¨ Storing Highest-Grossing Films in SQLite\n",
    "\n",
    "## Overview\n",
    "This script:\n",
    "- Creates a **SQLite database** (`highest_films.db`) if it doesn't exist.\n",
    "- Defines a table **`films`** to store movie details.\n",
    "- Reads **film data from JSON**.\n",
    "- Inserts the extracted data into the SQLite database.\n",
    "\n",
    "## Database Schema\n",
    "The table **`films`** has the following structure:\n",
    "- üÜî `id` - Unique ID (Primary Key)\n",
    "- üé• `title` - Film Title\n",
    "- üìÖ `release_year` - Year of Release\n",
    "- üé¨ `director` - Director Name\n",
    "- üí∞ `box_office` - Box Office Revenue\n",
    "- üåç `country` - Country of Origin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e68d7471-c5a0-43d1-b128-7dff3254a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "\n",
    "\n",
    "DB_FILE = \"highest_films.db\"\n",
    "\n",
    "\n",
    "conn = sqlite3.connect(DB_FILE)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS films (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    title TEXT NOT NULL,\n",
    "    release_year INTEGER,\n",
    "    director TEXT,\n",
    "    box_office TEXT,\n",
    "    country TEXT\n",
    ")\n",
    "''')\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "with open(\"highest_grossing_films.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    film_data = json.load(f)\n",
    "\n",
    "\n",
    "films_to_insert = [\n",
    "    (\n",
    "        film[\"title\"],\n",
    "        int(film[\"year\"]),\n",
    "        film[\"director\"],\n",
    "        film[\"box_office\"],\n",
    "        film[\"country\"]\n",
    "    )\n",
    "    for film in film_data\n",
    "]\n",
    "\n",
    "\n",
    "cursor.executemany(\"\"\"\n",
    "    INSERT INTO films (title, release_year, director, box_office, country)\n",
    "    VALUES (?, ?, ?, ?, ?)\n",
    "\"\"\", films_to_insert)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b463f428-56f9-420f-927b-6c9d23e3361d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d8caab-e8fb-4685-968e-3912ed91ce0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78e12147-06f8-45ee-8aec-525ac95acdce",
   "metadata": {},
   "source": [
    "## Check DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e294e199-b886-49db-b45a-a48cbba7f28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Avatar', 2009, 'James Cameron', '2923706026', 'United Kingdom, United States')\n",
      "(2, 'Avengers: Endgame', 2019, 'Anthony RussoJoe Russo', '2797501328', 'United States')\n",
      "(3, 'Avatar: The Way of Water', 2022, 'James Cameron', '2320250281', 'United States')\n",
      "(4, 'Titanic', 1997, 'James Cameron', '2257844554', 'United States')\n",
      "(5, 'Star Wars: The Force Awakens', 2015, 'J. J. Abrams', '2068223624', 'United States')\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"highest_films.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Fetch and display data\n",
    "cursor.execute(\"SELECT * FROM films\")\n",
    "rows = cursor.fetchall()\n",
    "for row in rows[:5]:\n",
    "    print(row)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c573cd-c06c-4f62-9c6a-7c3805452a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
